{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9465782-8a84-460e-8f7c-75c6e884b48a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Natural Language Processing with Hugging Face Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37172809-46bf-4129-b342-8bc1cb83addd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (1.13.1+cpu)\n",
      "Requirement already satisfied: typing-extensions in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from torch) (4.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40a55bb4-4179-4fd3-b2d9-5faa21945720",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (1.13.1+cpu)\n",
      "Requirement already satisfied: typing-extensions in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from torch) (4.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d57eda93-f750-41e4-8f2b-e3530c3431da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df1bb616-1704-43ae-a406-8c8c929b1956",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (2.13.2)\n",
      "Requirement already satisfied: evaluate in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (0.4.1)\n",
      "Requirement already satisfied: transformers[sentencepiece] in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (4.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from datasets) (1.21.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from datasets) (2.29.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from datasets) (4.66.2)\n",
      "Requirement already satisfied: xxhash in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from datasets) (0.16.4)\n",
      "Requirement already satisfied: packaging in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from datasets) (4.11.4)\n",
      "Requirement already satisfied: responses<0.19 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: filelock in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from transformers[sentencepiece]) (3.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from transformers[sentencepiece]) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.4.2)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.2.0)\n",
      "Requirement already satisfied: protobuf<=3.20.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from transformers[sentencepiece]) (3.20.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from aiohttp->datasets) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from aiohttp->datasets) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.15.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets evaluate transformers[sentencepiece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88f63c38-c870-46c2-a4d6-35f32095a117",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacremoses in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (0.0.53)\n",
      "Requirement already satisfied: regex in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from sacremoses) (2023.12.25)\n",
      "Requirement already satisfied: six in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from sacremoses) (1.16.0)\n",
      "Requirement already satisfied: click in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from sacremoses) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from sacremoses) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from sacremoses) (4.66.2)\n",
      "Requirement already satisfied: importlib-metadata in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from click->sacremoses) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses) (4.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4149da7-6447-40fa-b66c-db554049fc6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b425dd36-ee68-4f94-957a-597a86c5b6a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd077be-3cc6-46e7-b65a-069934652cd6",
   "metadata": {},
   "source": [
    "### Let's Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa1d336-0e73-4a90-baa3-b09d2b790fcd",
   "metadata": {},
   "source": [
    "### Exercise 1 - Sentiment Analysis\n",
    "\n",
    "For sentiment analysis, we can also use a specific model that is better suited to our use case by providing the name of the model. For example, if we want a sentiment analysis model for tweets, we can specify the following model id: \"cardiffnlp/twitter-roberta-base-sentiment\". This model has been trained on ~58M tweets and fine-tuned for sentiment analysis with the \"TweetEval\" benchmark. The output labels for this model are: 0 -> Negative; 1 -> Neutral; 2 -> Positive.\n",
    "\n",
    "In this Exercise, use \"cardiffnlp/twitter-roberta-base-sentiment\" model pre-trained on tweets data, to analyze any tweet of choice. Optionally, use the default model (used in Example 1) on the same tweet, to see if the result will change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37d53473-a8fd-4537-9bde-8da6d4738d4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardiff NLP Twitter Roberta:\n",
      "Sentiment: LABEL_1\n",
      "Score: 0.5272255539894104\n"
     ]
    }
   ],
   "source": [
    "data = \"Artificial intelligence and automation are already causing friction in the workforce. Should schools revamp existing programs for topics like #AI, or are new research areas required?\"\n",
    "\n",
    "specific_model = pipeline(model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "results_specific = specific_model(data)\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "print(\"Cardiff NLP Twitter Roberta:\")\n",
    "print(f\"Sentiment: {results_specific[0]['label']}\")\n",
    "print(f\"Score: {results_specific[0]['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb9e3767-aaef-49ee-8539-19046c71ebe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model:\n",
      "Sentiment: NEGATIVE\n",
      "Score: 0.9989722967147827\n"
     ]
    }
   ],
   "source": [
    "data = \"Artificial intelligence and automation are already causing friction in the workforce. Should schools revamp existing programs for topics like #AI, or are new research areas required?\"\n",
    "\n",
    "original_model = pipeline(\"sentiment-analysis\")  \n",
    "results_original = original_model(data)\n",
    "\n",
    "print(\"Original Model:\")\n",
    "print(f\"Sentiment: {results_original[0]['label']}\")  \n",
    "print(f\"Score: {results_original[0]['score']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365bba5c-e362-4e60-8068-ec274b27299a",
   "metadata": {},
   "source": [
    "### Exercise 2 - Topic Classification\n",
    "\n",
    "In this Exercise, use any sentence of choice to classify it under any classes/ topics of choice. Use \"zero-shot-classification\" and specify the model=\"facebook/bart-large-mnli\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b3f036d-b4d4-407a-8829-4e8a7700cb24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': 'I like eating pie',\n",
       " 'labels': ['cake', 'Vegetables', 'education'],\n",
       " 'scores': [0.4752267599105835, 0.27782317996025085, 0.24695000052452087]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "classifier(\n",
    "    \"I like eating pie\",\n",
    "    candidate_labels=[\"Vegetables\", \"education\", \"cake\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82cc5d7-dfd6-4a6e-8c1e-72c6563e61ce",
   "metadata": {},
   "source": [
    "### Exercise 3 - Text Generation Models\n",
    "In this Exercise, use 'text-generator' and 'gpt2' model to complete any sentence. Define any desirable number of returned sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11aedabb-2bd3-45fc-872f-6a216bf292a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"I'm in Jambi now—I'm sure you've been there. You've got your\"},\n",
       " {'generated_text': \"I'm in Jambi now and I will be going by my usual rules, such as eating\"},\n",
       " {'generated_text': 'I\\'m in Jambi now!\" The two men had come to the site of Jambi'},\n",
       " {'generated_text': 'I\\'m in Jambi now. I\\'m not ready to die, I\\'m dead.\" ('},\n",
       " {'generated_text': 'I\\'m in Jambi now,\" says the boy. \"So I\\'m really hoping some of'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model = 'gpt2')\n",
    "generator(\"I'm in Jambi now\", max_length = 20, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5021f7ef-187d-4bbd-b314-0309b6ee840a",
   "metadata": {},
   "source": [
    "### Exercise 4 - Name Entity Recognition\n",
    "In this Exercise, use any sentence of choice to extract entities: person, location and organization, using Name Entity Recognition task, specify model as \"Jean-Baptiste/camembert-ner\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a2695c9-80e1-4064-a300-b0a6ddd92612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': 0.98433656, 'word': 'Rizki', 'start': 10, 'end': 16}, {'entity_group': 'LOC', 'score': 0.9981303, 'word': 'Jambi', 'start': 30, 'end': 36}]\n"
     ]
    }
   ],
   "source": [
    "nlp = pipeline(\"ner\", model=\"Jean-Baptiste/camembert-ner\", grouped_entities=True)\n",
    "example = \"My name is Rizki and I live in Jambi city\"\n",
    "\n",
    "ner_results = nlp(example)\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab2ab4a-3e98-4dcf-aa35-993ec0a8be9a",
   "metadata": {},
   "source": [
    "### Exercise 5 - Question Answering\n",
    "In this Exercise, use any sentence and a question of choice to extract some information, using \"distilbert-base-cased-distilled-squad\" model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cf97112-5fdc-4b52-afbd-0f8664cb1090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.6591984629631042,\n",
       " 'start': 34,\n",
       " 'end': 52,\n",
       " 'answer': 'Sumatra, Indonesia'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "question_answerer(\n",
    "    question=\"Where is Jambi located??\",\n",
    "    context=\"Jambi is located on the island of Sumatra, Indonesia. To be precise, Jambi is in the central part of the island of Sumatra, on the east coast.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7571c999-c842-4cdb-8167-a47c2ecd2bce",
   "metadata": {},
   "source": [
    "### Exercise 6 - Text Summarization\n",
    "In this Exercise, use any document/paragraph of choice and summarize it, using \"sshleifer/distilbart-cnn-12-6\" model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92fb40d1-dec0-42e3-9f07-e8dd2b73cac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' The origin of the name \"Jambi\" has several versions . The name Jambi appeared when this area was ruled by Putri Selaras Pinang Masak, where the word \"pinang\" was called \"jambe\" in Old Javan'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "summarizer = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\",  max_length=56)\n",
    "summarizer(\n",
    "    \"\"\"The origin of the name \"Jambi\" has several versions. The first version, the name Jambi appeared when this area was ruled by Putri Selaras Pinang Masak, where the word \"pinang\" was called \"jambe\" in Old Javanese. The second version, the name Jambi comes from the many areca palm trees along the Batanghari River. The third version, the name Jambi is associated with the word \"jambi\" in Malay which means \"low land\".\n",
    "Regardless of which version is correct, Jambi has a long and rich history engraved in various cultural relics, such as the Muaro Jambi Temple and the Jambi Malay Kingdom..\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41052337-92d9-4ed5-991f-4989d811629c",
   "metadata": {},
   "source": [
    "### Exercise 7 - Translation\n",
    "In this Exercise, use any sentence of choice to translate English to German. The translation model you can use is \"translation_en_to_de\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35c18de1-b876-4b11-853a-08684426ef93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyterlab/conda/envs/python/lib/python3.7/site-packages/sklearn/utils/validation.py:37: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  LARGE_SPARSE_SUPPORTED = LooseVersion(scipy_version) >= '0.14.0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Fleischballs sind mein Lieblingsgericht'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "translator = pipeline(\"translation_en_to_de\", model=\"t5-small\")\n",
    "print(translator(\"Meatballs are my favorite food\", max_length=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88941dbf-38f6-4295-bf13-a3e04dadb908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
